{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "import seaborn as sns\n",
    "import heapq # for retrieval topK\n",
    "import multiprocessing\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from datetime import datetime\n",
    "from pprint import pprint \n",
    "from time import time\n",
    "from scipy.sparse.linalg import svds, eigs\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in log data and clean it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Negative_test_rating_19N.txt',\n",
      " 'etu_log.csv',\n",
      " 'Content-based.ipynb',\n",
      " 'Negative_test_rating_199N.txt',\n",
      " 'README.md',\n",
      " 'doc2_conversion_table.csv',\n",
      " 'cw-article.csv',\n",
      " 'doc1_viewing_columnExp.csv',\n",
      " 'doc1_viewing_history_cateID.csv',\n",
      " 'article_contents.csv',\n",
      " 'doc3_post_and_clicks.csv',\n",
      " 'DailyPost.csv',\n",
      " 'Negative_test_rating_50N.txt',\n",
      " 'EDA.ipynb',\n",
      " 'doc2_conversion_reference.csv',\n",
      " 'CF.ipynb',\n",
      " 'Negative_test_rating_99N.txt',\n",
      " 'doc1_viewing_data.csv']\n",
      "['output.json',\n",
      " 'optimization_test.py',\n",
      " 'multilingual.md',\n",
      " 'LICENSE',\n",
      " 'bert_train_data.ipynb',\n",
      " 'input.txt',\n",
      " 'tokenization.py',\n",
      " 'create_pretraining_data.py',\n",
      " 'README.md',\n",
      " 'optimization.py',\n",
      " 'run_pretraining.py',\n",
      " 'extract_features.py',\n",
      " 'requirements.txt',\n",
      " 'tokenization_test.py',\n",
      " 'chinese_L-12_H-768_A-12.zip',\n",
      " 'run_classifier.py',\n",
      " 'run_squad.py',\n",
      " 'sample_text.txt',\n",
      " 'bert_dev.p',\n",
      " '__init__.py',\n",
      " 'run_classifier_with_tfhub.py',\n",
      " 'CONTRIBUTING.md',\n",
      " 'bert_train.p',\n",
      " 'modeling.py',\n",
      " 'modeling_test.py',\n",
      " '.gitignore']\n",
      "['vocab.py', 'lm_dataset.py', 'dataset.py', '__init__.py']\n",
      "['vocab.cpython-36.pyc', '__init__.cpython-36.pyc']\n",
      "['bert_model.ckpt.index',\n",
      " 'bert_config.json',\n",
      " 'bert_model.ckpt.meta',\n",
      " 'bert_model.ckpt.data-00000-of-00001',\n",
      " 'vocab.txt']\n",
      "['vocab-checkpoint.txt', 'bert_config-checkpoint.json']\n",
      "['optimization.cpython-36.pyc',\n",
      " 'modeling.cpython-36.pyc',\n",
      " 'tokenization.cpython-36.pyc']\n",
      "['index', 'HEAD', 'packed-refs', 'description', 'config']\n",
      "[]\n",
      "[]\n",
      "['master']\n",
      "[]\n",
      "['HEAD']\n",
      "['commit-msg.sample',\n",
      " 'post-update.sample',\n",
      " 'applypatch-msg.sample',\n",
      " 'prepare-commit-msg.sample',\n",
      " 'update.sample',\n",
      " 'pre-applypatch.sample',\n",
      " 'pre-commit.sample',\n",
      " 'pre-rebase.sample',\n",
      " 'pre-push.sample']\n",
      "[]\n",
      "[]\n",
      "['pack-b6d12db212fde707abb21120c4a58265c745da8f.pack',\n",
      " 'pack-b6d12db212fde707abb21120c4a58265c745da8f.idx']\n",
      "[]\n",
      "['exclude']\n",
      "['HEAD']\n",
      "[]\n",
      "['master']\n",
      "[]\n",
      "['HEAD']\n",
      "['checkpoint',\n",
      " 'graph.pbtxt',\n",
      " 'train.tf_record',\n",
      " 'model.ckpt-114100.data-00000-of-00001',\n",
      " 'eval.tf_record',\n",
      " 'model.ckpt-114100.meta',\n",
      " 'model.ckpt-114100.index',\n",
      " 'events.out.tfevents.1561712249.jupyter-yaoting-40aiacademy-2etw',\n",
      " 'eval_results.txt']\n",
      "['events.out.tfevents.1561750545.jupyter-yaoting-40aiacademy-2etw']\n",
      "[]\n",
      "['create_pretraining_data-checkpoint.py',\n",
      " 'run_classifier-checkpoint.py',\n",
      " 'CONTRIBUTING-checkpoint.md',\n",
      " 'run_squad-checkpoint.py',\n",
      " 'bert_train_data-checkpoint.ipynb']\n",
      "['CF-checkpoint.ipynb',\n",
      " 'Content-based-checkpoint.ipynb',\n",
      " 'EDA-checkpoint.ipynb']\n",
      "[]\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 4359075: unexpected end of data\n"
     ]
    }
   ],
   "source": [
    "for root,dirs,files in os.walk('.'):\n",
    "    pprint(files)\n",
    "    file_list = files\n",
    "df_etu_log = pd.read_csv('etu_log.csv', engine = 'python',error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>act</th>\n",
       "      <th>cat</th>\n",
       "      <th>pid</th>\n",
       "      <th>eruid</th>\n",
       "      <th>keywords</th>\n",
       "      <th>url</th>\n",
       "      <th>hostname</th>\n",
       "      <th>agent</th>\n",
       "      <th>predn</th>\n",
       "      <th>preurl</th>\n",
       "      <th>lo</th>\n",
       "      <th>ssid</th>\n",
       "      <th>paywall</th>\n",
       "      <th>dates</th>\n",
       "      <th>eturec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:02</td>\n",
       "      <td>view</td>\n",
       "      <td>79.0</td>\n",
       "      <td>5088277.0</td>\n",
       "      <td>375b2a4d-6b06-c1aa-1cf6-a9472e820d65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.cw.com.tw/article/article.action?i...</td>\n",
       "      <td>www.cw.com.tw</td>\n",
       "      <td>Mozilla/5.0 (Linux; Android 6.0.1; HTC_D10u Bu...</td>\n",
       "      <td>m.facebook.com</td>\n",
       "      <td>http://m.facebook.com/</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8fa8df160d30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02-18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:01</td>\n",
       "      <td>view</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5087710.0</td>\n",
       "      <td>1be09de3-2363-1350-b095-221d37445280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.cw.com.tw/article/article.action?i...</td>\n",
       "      <td>www.cw.com.tw</td>\n",
       "      <td>Mozilla/5.0 (iPhone; CPU iPhone OS 11_2_5 like...</td>\n",
       "      <td>m.facebook.com</td>\n",
       "      <td>http://m.facebook.com</td>\n",
       "      <td>0.0</td>\n",
       "      <td>c0430e760562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02-18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:00:02</td>\n",
       "      <td>view</td>\n",
       "      <td>85.0</td>\n",
       "      <td>5088005.0</td>\n",
       "      <td>ced1cce8-08cc-0e84-82ec-b1b1ce6f32a0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.cw.com.tw/article/article.action?i...</td>\n",
       "      <td>www.cw.com.tw</td>\n",
       "      <td>Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_1 like...</td>\n",
       "      <td>m.facebook.com</td>\n",
       "      <td>http://m.facebook.com</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eed333bf3ef0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02-18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:00:02</td>\n",
       "      <td>view</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5088180.0</td>\n",
       "      <td>bde6bba0-bd52-e4b3-a17b-18cd72b02214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.cw.com.tw/article/article.action?i...</td>\n",
       "      <td>www.cw.com.tw</td>\n",
       "      <td>Mozilla/5.0 (iPhone; CPU iPhone OS 11_2_5 like...</td>\n",
       "      <td>m.facebook.com</td>\n",
       "      <td>http://m.facebook.com</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bb8b100b1fad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02-18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:00:01</td>\n",
       "      <td>view</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5081463.0</td>\n",
       "      <td>bb652779-3133-e1ec-5914-24d902b70197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.cw.com.tw/article/article.action?i...</td>\n",
       "      <td>www.cw.com.tw</td>\n",
       "      <td>Mozilla/5.0 (Linux; Android 6.0.1; CPH1611 Bui...</td>\n",
       "      <td>www.google.com.tw</td>\n",
       "      <td>https://www.google.com.tw/</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228acfd7c345</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02-18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       time   act   cat        pid                                 eruid  \\\n",
       "0  00:00:02  view  79.0  5088277.0  375b2a4d-6b06-c1aa-1cf6-a9472e820d65   \n",
       "1  00:00:01  view  11.0  5087710.0  1be09de3-2363-1350-b095-221d37445280   \n",
       "2  00:00:02  view  85.0  5088005.0  ced1cce8-08cc-0e84-82ec-b1b1ce6f32a0   \n",
       "3  00:00:02  view  11.0  5088180.0  bde6bba0-bd52-e4b3-a17b-18cd72b02214   \n",
       "4  00:00:01  view   7.0  5081463.0  bb652779-3133-e1ec-5914-24d902b70197   \n",
       "\n",
       "  keywords                                                url       hostname  \\\n",
       "0      NaN  https://www.cw.com.tw/article/article.action?i...  www.cw.com.tw   \n",
       "1      NaN  https://www.cw.com.tw/article/article.action?i...  www.cw.com.tw   \n",
       "2      NaN  https://www.cw.com.tw/article/article.action?i...  www.cw.com.tw   \n",
       "3      NaN  https://www.cw.com.tw/article/article.action?i...  www.cw.com.tw   \n",
       "4      NaN  https://www.cw.com.tw/article/article.action?i...  www.cw.com.tw   \n",
       "\n",
       "                                               agent              predn  \\\n",
       "0  Mozilla/5.0 (Linux; Android 6.0.1; HTC_D10u Bu...     m.facebook.com   \n",
       "1  Mozilla/5.0 (iPhone; CPU iPhone OS 11_2_5 like...     m.facebook.com   \n",
       "2  Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_1 like...     m.facebook.com   \n",
       "3  Mozilla/5.0 (iPhone; CPU iPhone OS 11_2_5 like...     m.facebook.com   \n",
       "4  Mozilla/5.0 (Linux; Android 6.0.1; CPH1611 Bui...  www.google.com.tw   \n",
       "\n",
       "                       preurl   lo          ssid paywall       dates  eturec  \n",
       "0      http://m.facebook.com/  0.0  8fa8df160d30     NaN  2018-02-18     NaN  \n",
       "1       http://m.facebook.com  0.0  c0430e760562     NaN  2018-02-18     NaN  \n",
       "2       http://m.facebook.com  0.0  eed333bf3ef0     NaN  2018-02-18     NaN  \n",
       "3       http://m.facebook.com  0.0  bb8b100b1fad     NaN  2018-02-18     NaN  \n",
       "4  https://www.google.com.tw/  0.0  228acfd7c345     NaN  2018-02-18     NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_etu_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start preprocessing\n",
      "Done_1,df_shape is : (2154549, 16)\n",
      "Done_2,df_shape is : (1993796, 16)\n",
      "Done_3,df_shape is : (1993796, 16)\n",
      "Done_4,df_shape is : (1993796, 17)\n"
     ]
    }
   ],
   "source": [
    "def del_df_columns_list(df,column_name,name_list,way_is_1=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    it can only delete one columns once \n",
    "    \"\"\"\n",
    "    if way_is_1 == True:\n",
    "        for i in name_list:\n",
    "            df = df[df[column_name] != i]\n",
    "    else:\n",
    "    #     below is the pd.merge way to merge data, but sometime coz pd will mislead the columns due to dtypes\n",
    "    #     If using the merge way, we should get the list that we want to PERSERVE.    \n",
    "        d = pd.DataFrame(data = name_list, columns = [column_name])\n",
    "        df = pd.merge(df, d, how = 'inner', on = [column_name])\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('start preprocessing')\n",
    "### Delete the unique user with click time less than 2, for 1 clicking user for CF-model is useless\n",
    "del_list = df_etu_log.eruid.value_counts()[(df_etu_log.eruid.value_counts() > 2) & (df_etu_log.eruid.value_counts() < 90*50)].keys()\n",
    "df_etu_log = del_df_columns_list(df_etu_log,'eruid',del_list,way_is_1 = False)\n",
    "print('Done_1,df_shape is :',df_etu_log.shape)\n",
    "### Drop the na-value in pid,eruid\n",
    "df_etu_log = df_etu_log.dropna(subset = ['pid','eruid'],how = 'any')\n",
    "print('Done_2,df_shape is :',df_etu_log.shape)\n",
    "### The time format should be like '**-**-**', so we filter out those length not equal to 8.\n",
    "del_list = list(set([i for i in df_etu_log.time if len(i)!=8])) \n",
    "df_etu_log = del_df_columns_list(df_etu_log,'time',del_list)\n",
    "print('Done_3,df_shape is :',df_etu_log.shape)\n",
    "### Creating the column using both time and date\n",
    "df_etu_log['datetime'] = df_etu_log['dates'] +'-'+ df_etu_log['time']\n",
    "print('Done_4,df_shape is :',df_etu_log.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hit rate / NDCG\n",
    "### reference : https://www.comp.nus.edu.sg/~xiangnan/papers/cikm15-trirank-cr.pdf\n",
    "\n",
    "def getHitRatio(ranklist, gtItem):\n",
    "    if gtItem in ranklist:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def getNDCG(ranklist, gtItem):\n",
    "    ar = np.array(ranklist)\n",
    "    if gtItem in ar:\n",
    "        return math.log(2) / math.log(np.where(ar == gtItem)[0][0] + 2)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_one_rating(idx, eval_mode,uim):\n",
    "    \n",
    "    '''''\n",
    "    eval_mode = 'Keras', 'ALS', 'matrix'\n",
    "    '''''\n",
    "    rating = _testRatings[idx]\n",
    "    ### rating should be like (  [user_id,article_pid(only one article, which is ground truth)]  ) \n",
    "    items = _testNegatives[idx][1]\n",
    "    ### items should be like (  [article_pid(19 ones, which are ones the reader haven't read)]  )\n",
    "    u = rating[0]\n",
    "    gtItem = rating[1]\n",
    "    items.append(gtItem)\n",
    "    \n",
    "    # Get prediction scores, the process is we offer 100(99 negative + 1 ground truth) articles to one user in testing data, and predict the score(read or not) and ranking.\n",
    "    map_item_score = {}\n",
    "    users = np.full(len(items), u, dtype = 'int32')\n",
    "    \n",
    "    if eval_mode == 'ALS':\n",
    "        predictions = _model.rank_items(u, uim.T, items)\n",
    "        items.pop()\n",
    "        ranklist = np.array(predictions, dtype = int)[:_K,0]\n",
    "        \n",
    "    else:\n",
    "        if eval_mode == 'Keras':\n",
    "            predictions = _model.predict([users, np.array(items)], \n",
    "                                         batch_size=100, verbose=0)\n",
    "        elif eval_mode == 'matrix':         \n",
    "            predictions = _model[u,items]\n",
    "\n",
    "\n",
    "        for i in range(len(items)):\n",
    "            item = items[i]\n",
    "            map_item_score[item] = predictions[i]\n",
    "        items.pop()\n",
    "        \n",
    "        # Evaluate top rank list\n",
    "        ranklist = heapq.nlargest(_K, map_item_score, key=map_item_score.get)\n",
    "        \n",
    "    hr = getHitRatio(ranklist, gtItem)\n",
    "    ndcg = getNDCG(ranklist, gtItem)\n",
    "    return (hr, ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables that are shared across processes\n",
    "_model = None\n",
    "_testRatings = None\n",
    "_testNegatives = None\n",
    "_K = None\n",
    "\n",
    "def evaluate_model(model, testRatings, testNegatives, K, num_thread, eval_mode = 'Keras', uim =None):\n",
    "    \"\"\"\n",
    "    Evaluate the performance (Hit_Ratio, NDCG) of top-K recommendation\n",
    "    Return: score of each test rating.\n",
    "    \"\"\"\n",
    "    global _model\n",
    "    global _testRatings\n",
    "    global _testNegatives\n",
    "    global _K\n",
    "    _model = model\n",
    "    _testRatings = testRatings\n",
    "    _testNegatives = testNegatives\n",
    "    _K = K\n",
    "        \n",
    "    hits, ndcgs = [],[]\n",
    "    if(num_thread > 1): # Multi-thread\n",
    "        pool = multiprocessing.Pool(processes=num_thread)\n",
    "        res = pool.map(eval_one_rating, range(len(_testRatings)))\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        hits = [r[0] for r in res]\n",
    "        ndcgs = [r[1] for r in res]\n",
    "        return (hits, ndcgs)\n",
    "    else:# Single thread\n",
    "        for idx in range(len(_testRatings)):\n",
    "            (hr,ndcg) = eval_one_rating(idx, eval_mode, uim)\n",
    "            hits.append(hr)\n",
    "            ndcgs.append(ndcg)      \n",
    "    return (hits, ndcgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Testing Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this section, I hope that I don't just randomly split the training/testing sets into 9:1.\n",
    "#### Rather, I will select those users with over 5 click times and pick the last click as the testing set.\n",
    "#### For example, index 1354 user has following reading history:{2,364,8796,4511,5,64}.\n",
    "#### This user history for {2,364,8796,4511,5} will be viewed as training set and 64 will be testing.\n",
    "#### Here testing means 1354 user did click into the article 64, and If the recommendation system provides the article in the recommending list, it means it succeed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_time(df , columns_1 , columns_2 , columns_time , ratio = 0.9):\n",
    "    '''\n",
    "    we will use the columns_1 as the first level index\n",
    "    sort the columns_2 as the target by columns_time\n",
    "    '''\n",
    "    \n",
    "    retreive_name = df[columns_1].value_counts()[df[columns_1].value_counts()>5].keys()\n",
    "    df_test = df[df[columns_1].isin(retreive_name)]\n",
    "    df_test = df_test.sort_values(columns_time).groupby(columns_1).tail(1)\n",
    "    df_train = df.drop(index=df_test.index)\n",
    "    \n",
    "    if df_test.shape[0] + df_train.shape[0] == df.shape[0]:\n",
    "        print('train_test_split succeed!! with df_train shape:(%d,%d), df_test shape:(%d,%d)'\n",
    "              %(df_train.shape[0],df_train.shape[1],df_test.shape[0],df_test.shape[1])\n",
    "             )\n",
    "        return df_train, df_test, retreive_name\n",
    "    else:\n",
    "        print('Oops, something wrong, with df_train shape : (%d,%d), df_test shape : (%d,%d)'\n",
    "              %(df_train.shape[0],df_train.shape[1],df_test.shape[0],df_test.shape[1])\n",
    "             )\n",
    "        print('df_shape : (%d,%d)'\n",
    "              %(df.shape[0],df.shape[1])\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_test_split succeed!! with df_train shape:(1894191,17), df_test shape:(99605,17)\n"
     ]
    }
   ],
   "source": [
    "df_train,df_test, retrieve = train_test_split_time(df_etu_log,'eruid','pid','datetime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will use the leave-one-out method to evaluate our testing data\n",
    "#### Basically, we will generate N samples list that the test user hasn't read and add the ground truth into the list, and see how the recommendation system will score and rank the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sampling(df_target,df_source,numbers_of_N_sample, generate_negative = False):\n",
    "    '''\n",
    "    1.\n",
    "    return: test_rating in the shape of [ [user_pid,article] *99605 ]\n",
    "    2.\n",
    "    from the target dataframe, sampling the negative sample from source dataframe\n",
    "    return: list in the shape of [ [(2(user_id,ground truth)) , [19(negative samples)] ]*99605]\n",
    "    '''\n",
    "    \n",
    "    test_rating = df_target[['eruid','pid']].values.tolist()\n",
    "    \n",
    "    print('test_rating yield successfully!!!')\n",
    "    \n",
    "    if generate_negative == True:\n",
    "        df_temp = df_source.drop_duplicates(subset = 'pid', keep = 'first')\n",
    "        negative_test_rating = []\n",
    "        for i in range(df_target.shape[0]):\n",
    "            drop_id = test_rating[i][0]\n",
    "            list_ = df_temp[df_temp['eruid'] != drop_id]['pid'].sample(numbers_of_N_sample).values.tolist()\n",
    "            \n",
    "            negative_test_rating.append([test_rating[i],list_])\n",
    "        print('negative_test_rating yield successfully!!!')\n",
    "\n",
    "        return test_rating, negative_test_rating\n",
    "    else:\n",
    "        return test_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only for generating sample, if there is a sample file already, skip this cell in the future\n"
     ]
    }
   ],
   "source": [
    "print('''only for generating sample, if there is a sample file already, skip this cell in the future''')\n",
    "### In the future just execute the next cell to get the test rating & negative sampling\n",
    "\n",
    "# time1 = time()\n",
    "# test_rating, negative_test_rating = get_sampling(df_test,df_train,19,True)\n",
    "# time2 = time()\n",
    "# print('Took for %d seconds' %(time2-time1))\n",
    "# with open(\"Negative_test_rating_19N.txt\",\"wb\") as f: #in write mode\n",
    "#     pickle.dump(negative_test_rating,f)\n",
    "\n",
    "    \n",
    "# ### For the simple model already kill(98% Hit Ratio) the dataset, so let's make it a bit harder\n",
    "# time1 = time()\n",
    "# test_rating, negative_test_rating = get_sampling(df_test,df_train,99,True)\n",
    "# time2 = time()\n",
    "# print('Took for %d seconds' %(time2-time1))\n",
    "# with open(\"Negative_test_rating_99N.txt\",\"wb\") as f: #in write mode\n",
    "#     pickle.dump(negative_test_rating,f)\n",
    "\n",
    "    \n",
    "### Experiment on my theory: whether the N samples in hit ratio is a parameters that needs to tune\n",
    "# time1 = time()\n",
    "# test_rating, negative_test_rating = get_sampling(df_test,df_train,199,True)\n",
    "# time2 = time()\n",
    "# print('Took for %d seconds' %(time2-time1))\n",
    "# with open(\"Negative_test_rating_199N.txt\",\"wb\") as f: #in write mode\n",
    "#     pickle.dump(negative_test_rating,f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_rating yield successfully!!!\n",
      "negative_test_rating yield successfully!!!\n",
      "Took for 4 seconds\n"
     ]
    }
   ],
   "source": [
    "time1 = time()\n",
    "test_rating = get_sampling(df_test,df_train,None)\n",
    "with open(\"Negative_test_rating_199N.txt\",'rb') as f: #in read mode, not in write mode, careful\n",
    "    negative_test_rating = pickle.load(f)\n",
    "    print('negative_test_rating yield successfully!!!')\n",
    "time2 = time()\n",
    "print('Took for %d seconds' %(time2-time1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_get_sampling(df_target,df_source, generate_negative = False):\n",
    "#     '''\n",
    "#     1.\n",
    "#     return: test_rating in the shape of [ [user_pid,article] *99605 ]\n",
    "#     2.\n",
    "#     from the target dataframe, sampling the negative sample from source dataframe\n",
    "#     return: list in the shape of [ [(2(user_id,ground truth)) , [19(negative samples)] ]*99605]\n",
    "#     '''\n",
    "    \n",
    "#     test_rating = df_target[['eruid','pid']].values.tolist()\n",
    "    \n",
    "#     print('test_rating yield successfully!!!')\n",
    "    \n",
    "#     if generate_negative == True:\n",
    "#         df_temp = df_source.drop_duplicates(subset = 'pid', keep = 'first')\n",
    "#         negative_test_rating = []\n",
    "#         for i in range(df_target.shape[0]):\n",
    "#             drop_id = test_rating[i][0]\n",
    "#             list_ = df_temp[df_temp['eruid'] != drop_id]['pid'].values.tolist()\n",
    "            \n",
    "#             negative_test_rating.append([test_rating[i],list_])\n",
    "#         print('negative_test_rating yield successfully!!!')\n",
    "\n",
    "#         return test_rating, negative_test_rating\n",
    "#     else:\n",
    "#         return test_rating\n",
    "    \n",
    "# time1 = time()\n",
    "# test_rating, negative_test_rating = test_get_sampling(df_test,df_train,True)\n",
    "# time2 = time()\n",
    "# print('Took for %d seconds' %(time2-time1))\n",
    "# with open(\"Negative_test_rating_allN.txt\",\"wb\") as f: #in write mode\n",
    "#     pickle.dump(negative_test_rating,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### In this part, we will first make the matrix to be like 1 for read once 0 for never-read \n",
    "df_train['read_time'] = 1\n",
    "df_test['read_time'] = 1\n",
    "df_train_group = df_train[['eruid','pid','read_time']].groupby(by = ['eruid','pid'],as_index=False).sum()\n",
    "df_test_group = df_test[['eruid','pid','read_time']].groupby(by = ['eruid','pid'],as_index=False).sum()\n",
    "\n",
    "### For the reason that normally people don't read articles more than 10 times\n",
    "cliper = 10\n",
    "df_train_group['read_time'] = df_train_group['read_time'].apply(lambda w: min(cliper,w))\n",
    "\n",
    "\n",
    "### To feed into the keras model, we have to turn both the eruid and pid into integer index\n",
    "eruid_map = {i:v for i,v in enumerate(df_etu_log.eruid.unique())}\n",
    "inverse_eruid_map = {v:i for i,v in enumerate(df_etu_log.eruid.unique())}\n",
    "pid_map = {i:v for i,v in enumerate(df_etu_log.pid.unique())}\n",
    "inverse_pid_map = {v:i for i,v in enumerate(df_etu_log.pid.unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eruid</th>\n",
       "      <th>pid</th>\n",
       "      <th>read_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002400-4800-5264-2ee9-bd655a0a91cd</td>\n",
       "      <td>5082394.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002400-4800-5264-2ee9-bd655a0a91cd</td>\n",
       "      <td>5087575.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00003620-4c40-2906-33ad-26cb9d5fe178</td>\n",
       "      <td>5053327.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00003620-4c40-2906-33ad-26cb9d5fe178</td>\n",
       "      <td>5055570.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00003620-4c40-2906-33ad-26cb9d5fe178</td>\n",
       "      <td>5068161.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  eruid        pid  read_time\n",
       "0  00002400-4800-5264-2ee9-bd655a0a91cd  5082394.0          1\n",
       "1  00002400-4800-5264-2ee9-bd655a0a91cd  5087575.0          1\n",
       "2  00003620-4c40-2906-33ad-26cb9d5fe178  5053327.0          1\n",
       "3  00003620-4c40-2906-33ad-26cb9d5fe178  5055570.0          1\n",
       "4  00003620-4c40-2906-33ad-26cb9d5fe178  5068161.0          1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### creating a mapping table for training data\n",
    "df_train_group_map = df_train_group.copy()\n",
    "df_test_group_map = df_test_group.copy()\n",
    "df_train_group_map['eruid'] = df_train_group['eruid'].map(inverse_eruid_map)\n",
    "df_train_group_map['pid'] = df_train_group['pid'].map(inverse_pid_map)\n",
    "df_test_group_map['eruid'] = df_test_group['eruid'].map(inverse_eruid_map)\n",
    "df_test_group_map['pid'] = df_test_group['pid'].map(inverse_pid_map)\n",
    "\n",
    "### creating a mapping list for testing data   \n",
    "test_rating_map = []\n",
    "for i in range(len(test_rating)):\n",
    "    test_rating_map.append([inverse_eruid_map[test_rating[i][0]],inverse_pid_map[test_rating[i][1]]])\n",
    "\n",
    "\n",
    "### creating a mapping list for negative testing data\n",
    "negative_test_rating_map = []\n",
    "for i in range(len(negative_test_rating)):\n",
    "    negative_test_rating_map.append([\n",
    "                                     [inverse_eruid_map[negative_test_rating[i][0][0]],inverse_pid_map[negative_test_rating[i][0][1]]],\n",
    "                                     list(map(lambda w:inverse_pid_map[w],negative_test_rating[i][1]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train_group_map shape:  (1555002, 3)\n",
      "number of users:  368598\n",
      "number of items:  19988\n",
      "The sparse matrix is one with shape (368598 , 19988), with 1555002 non-zero read_times\n"
     ]
    }
   ],
   "source": [
    "print('df_train_group_map shape: ',df_train_group_map.shape)\n",
    "print('number of users: ', len(eruid_map.items()))\n",
    "print('number of items: ', len(pid_map.items()))\n",
    "print('The sparse matrix is one with shape (%d , %d), with %d non-zero read_times'\n",
    "      %(len(eruid_map.items()),len(pid_map.items()),df_train_group_map.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Reshape, Flatten\n",
    "from keras.layers.merge import Multiply, multiply, Concatenate\n",
    "from keras.layers.merge import Dot\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras import optimizers\n",
    "from keras.regularizers import l2\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adagrad, Adam, SGD, RMSprop, Adadelta\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_users, num_items, latent_dim, regs=[0,0]):\n",
    "    ### define placeholder.\n",
    "    user_id_input = Input(shape=[1], name='user')\n",
    "    item_id_input = Input(shape=[1], name='item')\n",
    "\n",
    "    ### define embedding size and layers.\n",
    "\n",
    "    user_embedding = Embedding(output_dim = latent_dim, input_dim = num_users,\n",
    "                               input_length=1, name='user_embedding',\n",
    "                               embeddings_regularizer = l2(regs[0]))(user_id_input)\n",
    "    item_embedding = Embedding(output_dim = latent_dim, input_dim = num_items,\n",
    "                               input_length=1, name='item_embedding',\n",
    "                              embeddings_regularizer = l2(regs[1]))(item_id_input)\n",
    "\n",
    "    user_vecs = Reshape([latent_dim])(user_embedding)\n",
    "    item_vecs = Reshape([latent_dim])(item_embedding)\n",
    "\n",
    "    ### The prediction, which we calculate the loss function with ground truth and optimize.\n",
    "    y_hat = Dot(1, normalize=False)([user_vecs, item_vecs])\n",
    "\n",
    "    model = Model(inputs=[user_id_input, item_id_input], outputs=y_hat)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 [5.2 s]: HR = 0.3853, NDCG = 0.2763, val_loss = 0.9808 [112.1 s]\n",
      "Iteration 1 [1.9 s]: HR = 0.6540, NDCG = 0.4681, val_loss = 0.4131 [112.4 s]\n",
      "Iteration 2 [1.9 s]: HR = 0.6675, NDCG = 0.4808, val_loss = 0.1149 [112.2 s]\n",
      "Iteration 3 [1.9 s]: HR = 0.6564, NDCG = 0.4597, val_loss = 0.0897 [111.4 s]\n",
      "Iteration 4 [1.9 s]: HR = 0.6151, NDCG = 0.4232, val_loss = 0.1025 [111.7 s]\n",
      "Iteration 5 [1.9 s]: HR = 0.5762, NDCG = 0.3945, val_loss = 0.1304 [110.7 s]\n",
      "Iteration 6 [1.9 s]: HR = 0.5438, NDCG = 0.3715, val_loss = 0.1669 [110.8 s]\n",
      "End. Best Iteration 2:  HR = 0.6675, NDCG = 0.4808. \n"
     ]
    }
   ],
   "source": [
    "num_users = len(eruid_map.items())\n",
    "num_items = len(pid_map.items())\n",
    "topK = 5\n",
    "verbose = 0\n",
    "latent_dim = 15\n",
    "epochs = 100\n",
    "batch_size = 4096\n",
    "evaluation_threads = 1\n",
    "best_hr, best_ndcg, best_iter = -1, -1, -1\n",
    "model_out_file = 'models/GMF_%d_%d.h5' %(latent_dim, time())\n",
    "testRatings, testNegatives = test_rating_map, negative_test_rating_map\n",
    "learning_rate = 0.001\n",
    "model = get_model(num_users, num_items, latent_dim, regs=[0,0])\n",
    "model.compile(optimizer=Adam(lr=learning_rate), loss='mse') ### In this task, for label is 'read times'(integers from 0 -> 3XXX), so we use MSE as loss to optimize,\n",
    "                                                            ### However, if there is 'read or not-read'(integers 0 and 1), we should use 'binary cross-entropy'\n",
    "                                                            ### P.S. If using 'binary cross-entropy' in 'read times' task, I get the weird result with negative l\n",
    "hr_list = []\n",
    "loss_list = []\n",
    "patience = 5\n",
    "early_stop =True\n",
    "\n",
    "\n",
    "# Generate training instances\n",
    "user_input, item_input, labels = df_train_group_map.eruid, df_train_group_map.pid, df_train_group_map.read_time\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    t1 = time()\n",
    "        \n",
    "    # Training\n",
    "    hist = model.fit([np.array(user_input), np.array(item_input)], #input\n",
    "                         np.array(labels), # labels \n",
    "                         batch_size = batch_size,\n",
    "                         validation_data = ( [df_test_group_map.eruid,df_test_group_map.pid],df_test_group_map.read_time) ,\n",
    "                         epochs = 1, verbose = verbose, shuffle = True)\n",
    "    t2 = time()\n",
    "        \n",
    "    # Evaluation\n",
    "    (hits, ndcgs) = evaluate_model(model, testRatings, testNegatives, topK, evaluation_threads)\n",
    "    hr, ndcg, loss = np.array(hits).mean(), np.array(ndcgs).mean(), hist.history['val_loss'][0]    \n",
    "    hr_list.append(hr)\n",
    "    loss_list.append(loss)\n",
    "    # Using patience to set the early stopping.\n",
    "    # Always to save the model with minimun loss.\n",
    "    if hr < np.max(hr_list):\n",
    "        patience_count += 1\n",
    "    else:\n",
    "        patience_count = 0\n",
    "        best_hr, best_ndcg, best_iter = hr, ndcg, epoch\n",
    "        model.save_weights(model_out_file, overwrite=True)\n",
    "    if (early_stop) and (patience_count == patience):\n",
    "        break\n",
    "    if epoch % 1 == 0:\n",
    "        print('Iteration %d [%.1f s]: HR = %.4f, NDCG = %.4f, val_loss = %.4f [%.1f s]' \n",
    "            % (epoch,  t2-t1, hr, ndcg, loss, time()-t2))\n",
    "        \n",
    "print(\"End. Best Iteration %d:  HR = %.4f, NDCG = %.4f. \" %(best_iter, best_hr, best_ndcg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f73c338b1d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style('darkgrid')\n",
    "plt.plot(hr_list, label = 'Hit Ratio')\n",
    "plt.plot(loss_list, label = 'Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import SVG\n",
    "# from keras.utils.vis_utils import model_to_dot\n",
    "# from keras.utils import plot_model\n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "# # import pydot\n",
    "# SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Non-negative Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.constraints import non_neg\n",
    "\n",
    "def get_NMF_model(num_users, num_items, latent_dim, regs=[0,0]):\n",
    "    ### define placeholder.\n",
    "    user_id_input = Input(shape=[1], name='user')\n",
    "    item_id_input = Input(shape=[1], name='item')\n",
    "\n",
    "    ### define embedding size and layers.\n",
    "\n",
    "    user_embedding = Embedding(output_dim = latent_dim, input_dim = num_users,\n",
    "                               input_length=1, name='user_embedding_NMF', embeddings_constraint = non_neg(),\n",
    "                               embeddings_regularizer = l2(regs[0]))(user_id_input)\n",
    "    item_embedding = Embedding(output_dim = latent_dim, input_dim = num_items,\n",
    "                               input_length=1, name='item_embedding_NMF', embeddings_constraint = non_neg(),\n",
    "                              embeddings_regularizer = l2(regs[1]))(item_id_input)\n",
    "\n",
    "    user_vecs = Reshape([latent_dim])(user_embedding)\n",
    "    item_vecs = Reshape([latent_dim])(item_embedding)\n",
    "\n",
    "    ### The prediction, which we calculate the loss function with ground truth and optimize.\n",
    "    y_hat = Dot(1, normalize=False)([user_vecs, item_vecs])\n",
    "\n",
    "    model = Model(inputs=[user_id_input, item_id_input], outputs=y_hat)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 [5.5 s]: HR = 0.6480, NDCG = 0.4604,val_loss = 0.4455 [107.8 s]\n",
      "Iteration 1 [2.0 s]: HR = 0.6602, NDCG = 0.4740,val_loss = 0.0863 [106.7 s]\n",
      "Iteration 2 [2.0 s]: HR = 0.6527, NDCG = 0.4507,val_loss = 0.0815 [106.7 s]\n",
      "Iteration 3 [2.0 s]: HR = 0.6314, NDCG = 0.4151,val_loss = 0.1038 [106.7 s]\n",
      "Iteration 4 [2.0 s]: HR = 0.6036, NDCG = 0.3821,val_loss = 0.1331 [106.8 s]\n",
      "Iteration 5 [2.0 s]: HR = 0.5707, NDCG = 0.3522,val_loss = 0.1641 [106.6 s]\n",
      "End. Best Iteration 1:  HR = 0.6602, NDCG = 0.4740. \n"
     ]
    }
   ],
   "source": [
    "num_users = len(eruid_map.items())\n",
    "num_items = len(pid_map.items())\n",
    "topK = 5\n",
    "verbose = 0\n",
    "latent_dim = 15\n",
    "epochs = 100\n",
    "batch_size = 4096\n",
    "evaluation_threads = 1\n",
    "best_hr, best_ndcg, best_iter = -1, -1, -1\n",
    "model_out_file = 'models/NMF_%d_%d.h5' %(latent_dim, time())\n",
    "testRatings, testNegatives = test_rating_map, negative_test_rating_map\n",
    "learning_rate = 0.001\n",
    "model = get_NMF_model(num_users, num_items, latent_dim, regs=[0,0])\n",
    "model.compile(optimizer=Adam(lr=learning_rate), loss='mse') ### In this task, for label is 'read times'(integers from 0 -> 3XXX), so we use MSE as loss to optimize,\n",
    "                                                            ### However, if there is 'read or not-read'(integers 0 and 1), we should use 'binary cross-entropy'\n",
    "                                                            ### P.S. If using 'binary cross-entropy' in 'read times' task, I get the weird result with negative l\n",
    "hr_list = []\n",
    "patience = 5\n",
    "early_stop =True\n",
    "\n",
    "\n",
    "# Generate training instances\n",
    "user_input, item_input, labels = df_train_group_map.eruid, df_train_group_map.pid, df_train_group_map.read_time\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    t1 = time()\n",
    "        \n",
    "    # Training\n",
    "    hist = model.fit([np.array(user_input), np.array(item_input)], #input\n",
    "                         np.array(labels), # labels \n",
    "                         validation_data = ( [df_test_group_map.eruid,df_test_group_map.pid],df_test_group_map.read_time) ,\n",
    "                         batch_size = batch_size,\n",
    "                         epochs = 1, verbose = verbose, shuffle = True)\n",
    "    t2 = time()\n",
    "        \n",
    "    # Evaluation\n",
    "    (hits, ndcgs) = evaluate_model(model, testRatings, testNegatives, topK, evaluation_threads)\n",
    "    hr, ndcg, loss = np.array(hits).mean(), np.array(ndcgs).mean(), hist.history['val_loss'][0]    \n",
    "    hr_list.append(hr)\n",
    "    # Using patience to set the early stopping.\n",
    "    # Always to save the model with minimun loss.\n",
    "    if hr < np.max(hr_list):\n",
    "        patience_count += 1\n",
    "    else:\n",
    "        patience_count = 0\n",
    "        best_hr, best_ndcg, best_iter = hr, ndcg, epoch\n",
    "        model.save_weights(model_out_file, overwrite=True)\n",
    "    if (early_stop) and (patience_count == patience):\n",
    "        break\n",
    "    if epoch % 1 == 0:\n",
    "        print('Iteration %d [%.1f s]: HR = %.4f, NDCG = %.4f,val_loss = %.4f [%.1f s]' \n",
    "            % (epoch,  t2-t1, hr, ndcg, loss, time()-t2))\n",
    "        \n",
    "print(\"End. Best Iteration %d:  HR = %.4f, NDCG = %.4f. \" %(best_iter, best_hr, best_ndcg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scipy Singular Value Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD with U shape:(368598,15), S_mat shape:(15,15), Vt shape:(15,19988), [57.7 s]\n",
      "HR = 0.6491, NDCG = 0.4725 [9.9 s]\n"
     ]
    }
   ],
   "source": [
    "# For I've tried Tensorflow tf.svd, but it quickly OOM when using\n",
    "# I've also tried 'surprise' API, but its method 'predict' returns weird value so I couldn't calculate hr/ndcg\n",
    "\n",
    "### To build the user-item(-rating) matrix(uim) for SVD and evaluate the predicted matrix\n",
    "topK = 5\n",
    "verbose = 0\n",
    "evaluation_threads = 1\n",
    "nb_users = len(eruid_map.items())\n",
    "nb_articles = len(pid_map.items())\n",
    "nb_factors = 15\n",
    "model_out_file = 'models/SVD_%d_%d.h5' %(nb_factors, time())\n",
    "uim = np.zeros((nb_users, nb_articles), dtype=np.float32)\n",
    "uim[df_train_group_map.eruid, df_train_group_map.pid] = df_train_group_map.read_time\n",
    "\n",
    "time_1 = time()\n",
    "### From here, we use scipy.sparse.linalg.svds to decompose the uim matrix into U, S, Vt matrix.\n",
    "### k parameters stand for how many 'ranks'(signular values) we want to preserve. \n",
    "U, S, Vt = svds(uim, k = nb_factors)\n",
    "S_mat = np.diag(S)\n",
    "rating_matrix_hat = U@S_mat@Vt\n",
    "\n",
    "print('SVD with U shape:(%d,%d), S_mat shape:(%d,%d), Vt shape:(%d,%d), [%.1f s]'\n",
    "      %(U.shape[0],U.shape[1],S_mat.shape[0],S_mat.shape[1],Vt.shape[0],Vt.shape[1], time()-time_1)\n",
    "     )\n",
    "\n",
    "### Evaluating\n",
    "testRatings, testNegatives = test_rating_map, negative_test_rating_map\n",
    "time1 = time()\n",
    "(hits, ndcgs) = evaluate_model(rating_matrix_hat, testRatings, testNegatives, topK, evaluation_threads,\n",
    "                               eval_mode = 'matrix')\n",
    "hr, ndcg = np.array(hits).mean(), np.array(ndcgs).mean()\n",
    "\n",
    "print('HR = %.4f, NDCG = %.4f [%.1f s]' % (hr, ndcg, time()-time1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Neural Matrix Factorization (Neural CF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "def init_normal(shape,name=None):\n",
    "    return initializers.VarianceScaling(scale=0.01, mode='fan_in', distribution='normal')(shape)\n",
    "\n",
    "def get_NeuralMF_model(num_users, num_items, latent_dim, layers_units ,regs=[0,0], reg_layers = [0,0]):\n",
    "    ### define placeholder.\n",
    "    num_layer = len(layers_units) #Number of layers in the MLP\n",
    "    # Input variables\n",
    "    user_input = Input(shape=(1,), dtype= 'int32', name='user_input')\n",
    "    item_input = Input(shape=(1,), dtype= 'int32', name='item_input')\n",
    "    \n",
    "    # Embedding layer\n",
    "    MF_Embedding_User = Embedding(input_dim=num_users, output_dim=latent_dim, name='mf_embedding_user',\n",
    "                                  embeddings_initializer = init_normal, embeddings_regularizer = l2(regs[0]), input_length=1)(user_input)\n",
    "    MF_Embedding_Item = Embedding(input_dim=num_items, output_dim=latent_dim, name='mf_embedding_item',\n",
    "                                  embeddings_initializer = init_normal, embeddings_regularizer =l2(regs[0]), input_length=1)(item_input) \n",
    "\n",
    "    MLP_Embedding_User = Embedding(input_dim=num_users, output_dim=int(layers_units[0]/2), name='mlp_embedding_user',\n",
    "                               embeddings_initializer = init_normal, embeddings_regularizer = l2(regs[0]), input_length=1)(user_input)\n",
    "    MLP_Embedding_Item = Embedding(input_dim=num_items, output_dim=int(layers_units[0]/2), name='mlp_embedding_item',\n",
    "                               embeddings_initializer = init_normal,embeddings_regularizer =l2(regs[0]), input_length=1)(item_input)   \n",
    "    \n",
    "    # MF part\n",
    "   \n",
    "    mf_user_latent = Reshape([latent_dim])(MF_Embedding_User)\n",
    "    mf_item_latent = Reshape([latent_dim])(MF_Embedding_Item)\n",
    "\n",
    "    # Element-wise product of user and item embeddings \n",
    "    mf_vector = multiply([mf_user_latent, mf_item_latent]) # element-wise multiply\n",
    "\n",
    "    # MLP part \n",
    "    concatenated = Concatenate()([MLP_Embedding_User, MLP_Embedding_Item])\n",
    "    mlp_vector = Flatten()(concatenated)\n",
    "    \n",
    "    # MLP layers\n",
    "    for idx in range(0, num_layer):\n",
    "        layer = Dense(layers_units[idx], kernel_regularizer= l2(reg_layers[idx]), activation='relu', name = 'layer%d' %idx,)\n",
    "        mlp_vector = layer(mlp_vector)\n",
    "\n",
    "    predict_vector =  Concatenate()([mf_vector, mlp_vector])\n",
    "    \n",
    "    # Final prediction layer\n",
    "    prediction = Dense(1, activation='selu', kernel_initializer='RandomNormal', name = \"prediction\")(predict_vector)\n",
    "    \n",
    "    model = Model(inputs=[user_input, item_input], \n",
    "                  outputs=prediction)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 [7.3 s]: HR = 0.0689, NDCG = 0.0480,val_loss = 3.1894 [152.0 s]\n",
      "Iteration 1 [3.2 s]: HR = 0.6460, NDCG = 0.4598,val_loss = 2.4127 [153.0 s]\n",
      "Iteration 2 [3.3 s]: HR = 0.6494, NDCG = 0.4633,val_loss = 1.8371 [152.9 s]\n",
      "Iteration 3 [3.2 s]: HR = 0.6493, NDCG = 0.4641,val_loss = 1.4063 [152.7 s]\n",
      "Iteration 4 [3.2 s]: HR = 0.6502, NDCG = 0.4644,val_loss = 1.0771 [152.4 s]\n",
      "Iteration 5 [3.2 s]: HR = 0.6503, NDCG = 0.4643,val_loss = 0.8205 [152.5 s]\n",
      "Iteration 6 [3.2 s]: HR = 0.6505, NDCG = 0.4646,val_loss = 0.6175 [152.5 s]\n",
      "Iteration 7 [3.2 s]: HR = 0.6513, NDCG = 0.4654,val_loss = 0.4555 [152.7 s]\n",
      "Iteration 8 [3.3 s]: HR = 0.6522, NDCG = 0.4663,val_loss = 0.3268 [153.0 s]\n",
      "Iteration 9 [3.2 s]: HR = 0.6529, NDCG = 0.4672,val_loss = 0.2265 [152.8 s]\n",
      "Iteration 10 [3.2 s]: HR = 0.6535, NDCG = 0.4681,val_loss = 0.1510 [152.9 s]\n",
      "Iteration 11 [3.2 s]: HR = 0.6538, NDCG = 0.4689,val_loss = 0.0975 [152.8 s]\n",
      "Iteration 12 [3.2 s]: HR = 0.6541, NDCG = 0.4697,val_loss = 0.0626 [152.5 s]\n",
      "Iteration 13 [3.2 s]: HR = 0.6545, NDCG = 0.4704,val_loss = 0.0426 [152.5 s]\n",
      "Iteration 14 [3.2 s]: HR = 0.6555, NDCG = 0.4715,val_loss = 0.0331 [152.7 s]\n",
      "Iteration 15 [3.2 s]: HR = 0.6563, NDCG = 0.4719,val_loss = 0.0304 [152.2 s]\n",
      "Iteration 16 [3.2 s]: HR = 0.6571, NDCG = 0.4721,val_loss = 0.0314 [152.5 s]\n",
      "Iteration 17 [3.2 s]: HR = 0.6572, NDCG = 0.4706,val_loss = 0.0344 [152.6 s]\n",
      "Iteration 18 [3.2 s]: HR = 0.6565, NDCG = 0.4683,val_loss = 0.0388 [152.4 s]\n",
      "Iteration 19 [3.2 s]: HR = 0.6558, NDCG = 0.4649,val_loss = 0.0441 [152.6 s]\n",
      "Iteration 20 [3.2 s]: HR = 0.6541, NDCG = 0.4612,val_loss = 0.0504 [153.1 s]\n",
      "Iteration 21 [3.2 s]: HR = 0.6521, NDCG = 0.4571,val_loss = 0.0574 [152.9 s]\n",
      "End. Best Iteration 17:  HR = 0.6572, NDCG = 0.4706. \n"
     ]
    }
   ],
   "source": [
    "num_users = len(eruid_map.items())\n",
    "num_items = len(pid_map.items())\n",
    "topK = 5\n",
    "verbose = 0\n",
    "latent_dim = 15\n",
    "layers_units = [30,1]\n",
    "epochs = 100\n",
    "batch_size = 4096\n",
    "evaluation_threads = 1\n",
    "best_hr, best_ndcg, best_iter = -1, -1, -1\n",
    "model_out_file = 'models/NeuralMF_%d_%d.h5' %(latent_dim, time())\n",
    "testRatings, testNegatives = test_rating_map, negative_test_rating_map\n",
    "learning_rate = 0.0001\n",
    "model = get_NeuralMF_model(num_users, num_items, latent_dim, layers_units, regs=[0,0], reg_layers=[0.1,0.1])\n",
    "model.compile(optimizer=Adam(lr=learning_rate), loss='mse') ### In this task, for label is 'read times'(integers from 0 -> 3XXX), so we use MSE as loss to optimize,\n",
    "                                                            ### However, if there is 'read or not-read'(integers 0 and 1), we should use 'binary cross-entropy'\n",
    "                                                            ### P.S. If using 'binary cross-entropy' in 'read times' task, I get the weird result with negative l\n",
    "hr_list = []\n",
    "loss_list = []\n",
    "patience = 5\n",
    "early_stop =True\n",
    "\n",
    "\n",
    "# Generate training instances\n",
    "user_input, item_input, labels = df_train_group_map.eruid, df_train_group_map.pid, df_train_group_map.read_time\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    t1 = time()\n",
    "        \n",
    "    # Trainingon\n",
    "    hist = model.fit([np.array(user_input), np.array(item_input)], #input\n",
    "                         np.array(labels), # labels \n",
    "                         validation_data = ( [df_test_group_map.eruid,df_test_group_map.pid],df_test_group_map.read_time) ,\n",
    "                         batch_size = batch_size,\n",
    "                         epochs = 1, verbose = verbose, shuffle = True)\n",
    "    t2 = time()\n",
    "        \n",
    "    # Evaluation\n",
    "    (hits, ndcgs) = evaluate_model(model, testRatings, testNegatives, topK, evaluation_threads)\n",
    "    hr, ndcg, loss = np.array(hits).mean(), np.array(ndcgs).mean(), hist.history['val_loss'][0]    \n",
    "    hr_list.append(hr)\n",
    "    loss_list.append(loss)\n",
    "    # Using patience to set the early stopping.\n",
    "    # Always to save the model with minimun loss.\n",
    "    if hr < np.max(hr_list):\n",
    "        patience_count += 1\n",
    "    else:\n",
    "        patience_count = 0\n",
    "        best_hr, best_ndcg, best_iter = hr, ndcg, epoch\n",
    "        model.save_weights(model_out_file, overwrite=True)\n",
    "    if (early_stop) and (patience_count == patience):\n",
    "        break\n",
    "    if epoch % 1 == 0:\n",
    "        print('Iteration %d [%.1f s]: HR = %.4f, NDCG = %.4f,val_loss = %.4f [%.1f s]' \n",
    "            % (epoch,  t2-t1, hr, ndcg, loss, time()-t2))\n",
    "        \n",
    "print(\"End. Best Iteration %d:  HR = %.4f, NDCG = %.4f. \" %(best_iter, best_hr, best_ndcg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd3c75b4a90>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style('darkgrid')\n",
    "plt.plot(hr_list, label = 'Hit Ratio')\n",
    "plt.plot(loss_list, label = 'Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_input (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_input (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mlp_embedding_user (Embedding)  (None, 1, 15)        5528970     user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mlp_embedding_item (Embedding)  (None, 1, 15)        299820      item_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1, 30)        0           mlp_embedding_user[0][0]         \n",
      "                                                                 mlp_embedding_item[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "mf_embedding_user (Embedding)   (None, 1, 15)        5528970     user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mf_embedding_item (Embedding)   (None, 1, 15)        299820      item_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 30)           0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 15)           0           mf_embedding_user[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 15)           0           mf_embedding_item[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "layer0 (Dense)                  (None, 30)           930         flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 15)           0           reshape_3[0][0]                  \n",
      "                                                                 reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer1 (Dense)                  (None, 1)            31          layer0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 16)           0           multiply_1[0][0]                 \n",
      "                                                                 layer1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Dense)              (None, 1)            17          concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 11,658,558\n",
      "Trainable params: 11,658,558\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implicit Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I've built my own implicit feedback model but it's hard to train, so I chose to use the API from other great minds. The API 'implicit' is based 100% by the paper I refer and written in cython and has good performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting implicit\n",
      "Requirement already satisfied: scipy>=0.16 in /opt/conda/lib/python3.6/site-packages (from implicit) (1.1.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from implicit) (4.27.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from implicit) (1.15.2)\n",
      "Installing collected packages: implicit\n",
      "Successfully installed implicit-0.3.8\n"
     ]
    }
   ],
   "source": [
    "!pip install implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uim shape :  (19988, 368598)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15.0/15 [00:54<00:00,  3.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR = 0.7028, NDCG = 0.5361 [26.0 s], alpha = 195\n"
     ]
    }
   ],
   "source": [
    "nb_users = len(eruid_map.items())\n",
    "nb_articles = len(pid_map.items())\n",
    "uim = np.zeros((nb_users, nb_articles), dtype=np.float32)\n",
    "uim[df_train_group_map.eruid, df_train_group_map.pid] = df_train_group_map.read_time ### Here comes the point that we only \n",
    "                                                                                     ### use the training data to make the\n",
    "                                                                                     ### uim matrix\n",
    "\n",
    "from scipy import sparse as sp\n",
    "alpha = 195\n",
    "uim = uim + uim * alpha\n",
    "uim = sp.csr_matrix(uim.T) ### The API needs the rows to be items and the columns to be users \n",
    "print('uim shape : ',uim.shape)\n",
    "\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "\n",
    "model = AlternatingLeastSquares(factors=15,use_gpu=False)\n",
    "model.fit(item_users=uim)\n",
    "\n",
    "assert(model.user_factors.shape[0] == len(eruid_map))\n",
    "assert(model.item_factors.shape[0] == len(pid_map))\n",
    "\n",
    "### Evaluating\n",
    "topK = 5\n",
    "evaluation_threads = 1\n",
    "testRatings, testNegatives = test_rating_map, negative_test_rating_map\n",
    "time1 = time()\n",
    "(hits, ndcgs) = evaluate_model(model, testRatings, testNegatives, topK, evaluation_threads,\n",
    "                               eval_mode = 'ALS', uim = uim)\n",
    "hr, ndcg = np.array(hits).mean(), np.array(ndcgs).mean()\n",
    "print('HR = %.4f, NDCG = %.4f [%.1f s], alpha = %d' % (hr, ndcg, time()-time1, alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below it my personal attempt on building the implicit recommendation model under Keras framework, the result is far from the API and still needs time to fine-tune and debugs\n",
    "### In the paper, we need to transform the observation into confidence values, which includes two steps,\n",
    "### 1. Transform all missing values(those unobserved user-item pairs) into 0\n",
    "### 2. Customize the loss function into $\\min \\sum_{u,i}c_{ui}(p_{ui} - x_{u}^{T}y_{i})^{2} + \\lambda  \n",
    "(\\sum_{u}||x_{u}||^2 + \\sum_{i}||y_{i}||^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. Transform all missing value\n",
    "\n",
    "nb_users = len(eruid_map.items())\n",
    "nb_articles = len(pid_map.items())\n",
    "uim = np.zeros((nb_users, nb_articles), dtype=np.float32)\n",
    "uim[df_train_group_map.eruid, df_train_group_map.pid] = df_train_group_map.read_time ### Here comes the point that we only \n",
    "                                                                                     ### use the training data to make the\n",
    "                                                                                     ### uim matrix\n",
    "### 2. Customize loss function\n",
    "\n",
    "def Implicit_loss(alpha):\n",
    "    \n",
    "    def Loss_function(y_true, y_pred):\n",
    "        c = 1 + alpha * y_true\n",
    "#         Loss = K.mean(c * K.square(y_true - y_pred)) \n",
    "        Loss = c * K.square(y_true - y_pred) \n",
    "        ### The reason why we don't have to add the penalty term in 'Loss_function' is that we've done that in 'get_model' function,\n",
    "        ### the attribute 'embedding_regularizer' needs a value that stands for l2 norm with that value.\n",
    "        return Loss\n",
    "        \n",
    "    return Loss_function\n",
    "\n",
    "def uim_gen(uim, batch_size, eruid_map, pid_map):\n",
    "    row = [i for i in range(len(eruid_map))] * (len(pid_map) // 10)\n",
    "\n",
    "    col = [i for i in range(len(pid_map))] * (len(eruid_map) // 10)\n",
    "    \n",
    "    while True:\n",
    "        user_input_vector = np.array(random.sample(row,batch_size))\n",
    "        item_input_vector = np.array(random.sample(col,batch_size))\n",
    "        labels_vector = uim[user_input_vector,item_input_vector]\n",
    "        yield ([user_input_vector,item_input_vector],labels_vector)\n",
    "\n",
    "def get_model(num_users, num_items, latent_dim, regs=[0,0]):\n",
    "    ### define placeholder.\n",
    "    user_id_input = Input(shape=[1], name='user')\n",
    "    item_id_input = Input(shape=[1], name='item')\n",
    "\n",
    "    ### define embedding size and layers.\n",
    "\n",
    "    user_embedding = Embedding(output_dim = latent_dim, input_dim = num_users,\n",
    "                               input_length=1, name='user_embedding',\n",
    "                               embeddings_regularizer = l2(regs[0]))(user_id_input)\n",
    "    item_embedding = Embedding(output_dim = latent_dim, input_dim = num_items,\n",
    "                               input_length=1, name='item_embedding',\n",
    "                              embeddings_regularizer = l2(regs[1]))(item_id_input)\n",
    "\n",
    "    user_vecs = Reshape([latent_dim])(user_embedding)\n",
    "    item_vecs = Reshape([latent_dim])(item_embedding)\n",
    "\n",
    "    ### The prediction, which we calculate the loss function with ground truth and optimize.\n",
    "    y_hat = Dot(1, normalize=False)([user_vecs, item_vecs])\n",
    "\n",
    "    model = Model(inputs=[user_id_input, item_id_input], outputs=y_hat)\n",
    "    \n",
    "    return model\n",
    "\n",
    "### parameter setting&start training\n",
    "\n",
    "num_users = len(eruid_map.items())\n",
    "num_items = len(pid_map.items())\n",
    "topK = 5\n",
    "verbose = 0\n",
    "latent_dim = 15\n",
    "epochs = 100\n",
    "batch_size = 1024 * 1024\n",
    "evaluation_threads = 1\n",
    "best_hr, best_ndcg, best_iter = -1, -1, -1\n",
    "model_out_file = 'models/GMF_%d_%d.h5' %(latent_dim, time())\n",
    "testRatings, testNegatives = test_rating_map, negative_test_rating_map\n",
    "learning_rate = 0.01\n",
    "alpha = 120\n",
    "model = get_model(num_users, num_items, latent_dim, regs=[0,0])\n",
    "model.compile(optimizer=Adam(lr=learning_rate), loss=Implicit_loss(alpha = alpha)) ### In this task, for label is 'read times'(integers from 0 -> 3XXX), so we use MSE as loss to optimize,\n",
    "                                                            ### However, if there is 'read or not-read'(integers 0 and 1), we should use 'binary cross-entropy'\n",
    "                                                            ### P.S. If using 'binary cross-entropy' in 'read times' task, I get the weird result with negative l\n",
    "hr_list = []\n",
    "loss_list = []\n",
    "patience = 5\n",
    "early_stop =True\n",
    "\n",
    "\n",
    "# Generate training instances\n",
    "gen = uim_gen(uim, batch_size, eruid_map, pid_map)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    t1 = time()\n",
    "        \n",
    "    # Training\n",
    "    hist = model.fit_generator(gen,\n",
    "                         steps_per_epoch = (len(eruid_map) * len(pid_map)) // batch_size ,\n",
    "                         validation_data = ( [df_test_group_map.eruid,df_test_group_map.pid],df_test_group_map.read_time) ,\n",
    "                         epochs = 1, verbose = verbose, shuffle = True)\n",
    "    t2 = time()\n",
    "        \n",
    "    # Evaluation\n",
    "    (hits, ndcgs) = evaluate_model(model, testRatings, testNegatives, topK, evaluation_threads)\n",
    "    hr, ndcg, loss = np.array(hits).mean(), np.array(ndcgs).mean(), hist.history['val_loss'][0]    \n",
    "    hr_list.append(hr)\n",
    "    loss_list.append(loss)\n",
    "    # Using patience to set the early stopping.\n",
    "    # Always to save the model with minimun loss.\n",
    "    if hr < np.max(hr_list):\n",
    "        patience_count += 1\n",
    "    else:\n",
    "        patience_count = 0\n",
    "        best_hr, best_ndcg, best_iter = hr, ndcg, epoch\n",
    "        model.save_weights(model_out_file, overwrite=True)\n",
    "    if (early_stop) and (patience_count == patience):\n",
    "        break\n",
    "    if epoch % 1 == 0:\n",
    "        print('Iteration %d [%.1f s]: HR = %.4f, NDCG = %.4f, val_loss = %.4f [%.1f s]' \n",
    "            % (epoch,  t2-t1, hr, ndcg, loss, time()-t2))\n",
    "        \n",
    "print(\"End. Best Iteration %d:  HR = %.4f, NDCG = %.4f. \" %(best_iter, best_hr, best_ndcg))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
